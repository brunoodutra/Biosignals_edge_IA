{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Example of Quantization Model in H5 Format to TensorFlow Lite (tflite)\n",
    "\n",
    "## Overview\n",
    "In this experiment, we employ custom class functions, specifically `Embedded_Model` and `Embedded_Model_Conversion`, to perform the quantization and conversion of Keras models in H5 format to TensorFlow Lite (tflite) models. The resulting tflite models are intended for use in embedded environments.\n",
    "\n",
    "### Custom Class Functions\n",
    "- `Embedded_Model`: This custom class function is responsible for handling the quantization process of the Keras model. Quantization is a technique used to reduce the model's memory and computational requirements, making it suitable for resource-constrained environments.\n",
    "- `Embedded_Model_Conversion`: This custom class function handles the conversion of the quantized Keras model to the TensorFlow Lite (tflite) format. The tflite format is optimized for running on various edge devices, including embedded systems.\n",
    "\n",
    "The primary motivation behind this experiment is to prepare machine learning models for deployment in embedded environments, where computational resources may be limited. By quantizing and converting models to tflite format, we can ensure efficient and lightweight model execution without compromising on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [0. Packages](#0)\n",
    "    - [Custom packages](#0-1)\n",
    "    - [Pythom packages](#0-2)\n",
    "- [1. Load the origianl .h5 model](#1)\n",
    "- [2. Load the model's path and convert the oritinal model to tflite](#2)\n",
    "- [3. Load the saved tflite model](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"0\"></a>\n",
    "### Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"0-1\"></a>\n",
    "#### Custom packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "functions_source_path = os.path.abspath('./../functions/')\n",
    "if(functions_source_path not in sys.path):\n",
    "    sys.path.append(functions_source_path)\n",
    "\n",
    "from Embedded_Model import Embedded_Model\n",
    "from Embedded_Model_Convertion import Embedded_Model_Convertion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0-2\"></a>\n",
    "#### Pythom packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "### Load the original .h5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_model='EMG' # EMG\n",
    "option=1 # for EEG we have option 1= CNN1D and option 2 = CNN2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:55:40.051972: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 13:55:40.540289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 76549 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n",
      "2023-11-10 13:55:42.142130: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./../../../EMG/Experiments/Deep_learning/Train/trainings/Resnet2D/assets\n"
     ]
    }
   ],
   "source": [
    "if quantization_model== 'EMG':\n",
    "    # EMG models\n",
    "    model_name='Resnet2D.h5'\n",
    "    model_path='./../../../EMG/Experiments/Deep_learning/Train/trainings/'\n",
    "\n",
    "elif quantization_model== 'EEG':\n",
    "    #EEG models\n",
    "    if option ==1 :\n",
    "        model_name='SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights.h5'\n",
    "        model_path='./../../../EEG/Experiments/Deep_learning/Train/models/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/'\n",
    "    else option==2:\n",
    "        model_name='S1_21_Adam0.0001_factor2_D3.h5'\n",
    "        model_path='./../../../EEG/Experiments/Deep_learning/Train/test_model/'\n",
    "    \n",
    "    \n",
    "    \n",
    "#format_model='H5 file' # if the model was salved in path mode use 'path' to this parameter\n",
    "format_model='file'\n",
    "\n",
    "if 'path' in format_model:\n",
    "    model = keras.models.load_model(model_path+model_name)\n",
    "    model.save(model_path+model_name+'.h5')\n",
    "    model_name=model_name.split('.')[0]\n",
    "try:\n",
    "    AI_model=keras.models.load_model(model_path+model_name, compile=False)\n",
    "    AI_model.save(model_path+model_name.split('.')[0])\n",
    "except:\n",
    "    print(f'Problem to load the {model_path+model_name}. Make sure the path and model exist.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8, 8, 128)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 8, 8, 64)     73792       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 8, 8, 64)    256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 8, 8, 64)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 32)     18464       ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 32)    128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 8, 8, 32)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 8, 32)     1056        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 32)    128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 8, 8, 32)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " res_1 (Add)                    (None, 8, 8, 32)     0           ['activation_1[0][0]',           \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 32)    128         ['res_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 8, 8, 32)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 32)     1056        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 8, 8, 32)    128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 8, 8, 32)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " res_2 (Add)                    (None, 8, 8, 32)     0           ['activation_3[0][0]',           \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 8, 32)    128         ['res_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 8, 8, 32)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8, 8, 32)     0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          524544      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 256)         1024        ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 256)          0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256)          0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 256)         1024        ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 256)          0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           16448       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64)          256         ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64)           0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           650         ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 10)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 705,002\n",
      "Trainable params: 703,402\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AI_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2\"></a>\n",
    "\n",
    "### Load the model's path and convert the original model to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/IA-Algorithms/fx_bios_ia/fx_bios_ia/EEG/Experiments/Deep_learning/Train/models/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path+model_name.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPATIBILITY WARNING: op 'tf.Cosh' require(s) \"Select TF Ops\" for model conversion for TensorFlow Lite. https://www.tensorflow.org/lite/guide/ops_select\n",
      "Op: tf.Cosh\n",
      "  - /usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py:740\n",
      "  - /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py:2537\n",
      "  - /root/IA-Algorithms/fx_bios_ia/fx_bios_ia/embedded/Quantization/functions/Embedded_Model_Convertion.py:27\n",
      "\n",
      "result = [1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 12:03:36.962541: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2023-10-17 12:03:36.970548: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2023-10-17 12:03:36.976207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 66299 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:bd:00.0, compute capability: 8.0\n",
      "2023-10-17 12:03:36.997953: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1191] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.012ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "\n",
      "2023-10-17 12:03:37.024094: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-10-17 12:03:37.024130: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "loc(fused[\"Cosh:\", callsite(\"Cosh\"(\"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py\":740:0) at callsite(\"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py\":2537:0 at callsite(\"/root/IA-Algorithms/fx_bios_ia/fx_bios_ia/embedded/Quantization/functions/Embedded_Model_Convertion.py\":27:0 at callsite(\"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\":1136:0 at callsite(\"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\":677:0 at callsite(\"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\":1161:0 at callsite(\"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\":3130:0 at callsite(\"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\":3292:0 at callsite(\"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\":2983:0 at \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\":785:0)))))))))]): error: 'tf.Cosh' op is neither a custom op nor a flex op\n",
      "error: failed while converting: 'main': \n",
      "Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \n",
      "TF Select ops: Cosh\n",
      "Details:\n",
      "\ttf.Cosh(tensor<?xf32>) -> (tensor<?xf32>) : {device = \"\"}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A conversão do modelo durou 1.7149207592010498 segundos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 12:03:38.161327: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2023-10-17 12:03:38.161406: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2023-10-17 12:03:38.161682: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /root/IA-Algorithms/fx_bios_ia/fx_bios_ia/EEG/Experiments/Deep_learning/Train/models/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights\n",
      "2023-10-17 12:03:38.170998: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2023-10-17 12:03:38.171032: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /root/IA-Algorithms/fx_bios_ia/fx_bios_ia/EEG/Experiments/Deep_learning/Train/models/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights\n",
      "2023-10-17 12:03:38.203130: I tensorflow/cc/saved_model/loader.cc:230] Restoring SavedModel bundle.\n",
      "2023-10-17 12:03:38.305053: I tensorflow/cc/saved_model/loader.cc:214] Running initialization op on SavedModel bundle at path: /root/IA-Algorithms/fx_bios_ia/fx_bios_ia/EEG/Experiments/Deep_learning/Train/models/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights\n",
      "2023-10-17 12:03:38.346592: I tensorflow/cc/saved_model/loader.cc:321] SavedModel load for tags { serve }; Status: success: OK. Took 184911 microseconds.\n",
      "2023-10-17 12:03:38.411554: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-17 12:03:38.659037: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_5/MatMul because it has fewer than 1024 elements (512).\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "tflite_model=Embedded_Model_Convertion(model_path+model_name.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serving_default_emg_input:0 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/BiasAdd;conv1d/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/sub;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_1/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/BiasAdd;conv1d_1/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/sub;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_2/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/BiasAdd;conv1d_2/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/sub;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/Conv1D;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_5/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/BiasAdd;conv1d_3/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/sub;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/BiasAdd;conv1d/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D <class 'numpy.int8'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/BiasAdd;conv1d_1/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D <class 'numpy.int8'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/BiasAdd;conv1d_2/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/Conv1D;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D <class 'numpy.int8'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/BiasAdd;conv1d_3/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D <class 'numpy.int8'>\n",
      "dense_5/bias <class 'numpy.float32'>\n",
      "dense_2/bias <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d/ExpandDims/dim <class 'numpy.int32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/flatten/Const <class 'numpy.int32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D/ExpandDims/dim <class 'numpy.int32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_3/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_3/batchnorm/add_1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_4/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_4/batchnorm/add_1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_6/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_6/batchnorm/add_1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_7/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_7/batchnorm/add_1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_5/MatMul <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_2/MatMul <class 'numpy.int8'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d/Squeeze <class 'numpy.int32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D/Squeeze <class 'numpy.int32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d_1/Squeeze <class 'numpy.int32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D/Squeeze <class 'numpy.int32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_6/batchnorm/mul_1 <class 'numpy.int8'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_7/batchnorm/mul_1 <class 'numpy.int8'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_3/batchnorm/mul_1 <class 'numpy.int8'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_4/batchnorm/mul_1 <class 'numpy.int8'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D/ExpandDims <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/BiasAdd;conv1d/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/sub;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d/BiasAdd;conv1d/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization/batchnorm/sub <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d/ExpandDims <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d/MaxPool <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d/Squeeze1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D/ExpandDims <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_1/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/BiasAdd;conv1d_1/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/sub;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_1/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_1/BiasAdd;conv1d_1/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_1/batchnorm/sub <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d_1/ExpandDims <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d_1/MaxPool <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d_1/Squeeze1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/Conv1D/ExpandDims <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_2/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/BiasAdd;conv1d_2/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/sub;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/Conv1D;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_2/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_2/BiasAdd;conv1d_2/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_2/batchnorm/sub <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d_2/ExpandDims <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d_2/MaxPool <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/flatten/Reshape <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_5/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/BiasAdd;conv1d_3/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/sub;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_5/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/add_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/Conv1D/Squeeze;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/conv1d_3/BiasAdd;conv1d_3/bias;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/mul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_5/batchnorm/sub <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d_3/ExpandDims <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/max_pooling1d_3/MaxPool <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/flatten_1/Reshape <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_3/MatMul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_3/BiasAdd;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_6/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_6/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_6/batchnorm/add_1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_4/MatMul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_4/BiasAdd;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_7/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_7/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_7/batchnorm/add_1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_5/MatMul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_5/BiasAdd <class 'numpy.float32'>\n",
      "StatefulPartitionedCall:1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense/MatMul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense/BiasAdd;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_3/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_3/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_3/batchnorm/add_1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_1/MatMul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_1/BiasAdd;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_4/batchnorm/mul_1;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/activation_4/Relu;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/batch_normalization_4/batchnorm/add_1 <class 'numpy.float32'>\n",
      "SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_2/MatMul;SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights/dense_2/BiasAdd <class 'numpy.float32'>\n",
      "StatefulPartitionedCall:0 <class 'numpy.float32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      "Conv_row_sums <class 'numpy.int32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      "Conv_row_sums <class 'numpy.int32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      "Conv_row_sums <class 'numpy.int32'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.int8'>\n",
      " <class 'numpy.float32'>\n",
      " <class 'numpy.int32'>\n",
      " <class 'numpy.int32'>\n",
      "Conv_row_sums <class 'numpy.int32'>\n",
      "dict_keys(['name', 'index', 'shape', 'shape_signature', 'dtype', 'quantization', 'quantization_parameters', 'sparsity_parameters'])\n"
     ]
    }
   ],
   "source": [
    "tflite_model.print_model_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "### Load the saved tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model=Embedded_Model(model_path+model_name.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (56,16,8) into shape (512,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel output\u001b[39m\u001b[38;5;124m'\u001b[39m,tf_model\u001b[38;5;241m.\u001b[39mclassify_data(np\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m128\u001b[39m])))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m quantization_model\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEEG\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# EEG models\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel output\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mtf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m56\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/IA-Algorithms/fx_bios_ia/fx_bios_ia/embedded/Quantization/functions/Embedded_Model.py:45\u001b[0m, in \u001b[0;36mEmbedded_Model.classify_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124;03m''' Model classification method\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_input_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m                                                  \u001b[38;5;66;03m# Load data into Model Input Layer\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39minvoke()                                                    \u001b[38;5;66;03m# Runs Classification to data loaded on Input Layer\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     output_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39mget_output_details()                    \u001b[38;5;66;03m# Get model Output Layer expected data format \u001b[39;00m\n",
      "File \u001b[0;32m~/IA-Algorithms/fx_bios_ia/fx_bios_ia/embedded/Quantization/functions/Embedded_Model.py:32\u001b[0m, in \u001b[0;36mEmbedded_Model.set_input_tensor\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m tensor_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39mget_input_details()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m]   \u001b[38;5;66;03m# Get Input Layer expected data format \u001b[39;00m\n\u001b[1;32m     31\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39mtensor(tensor_index)()[\u001b[38;5;241m0\u001b[39m]         \n\u001b[0;32m---> 32\u001b[0m input_tensor[:, :] \u001b[38;5;241m=\u001b[39m data\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (56,16,8) into shape (512,8)"
     ]
    }
   ],
   "source": [
    "if quantization_model== 'EMG':\n",
    "    # EMG models\n",
    "    print('Model output',tf_model.classify_data(np.zeros([1,8,8,128])))\n",
    "\n",
    "elif quantization_model== 'EEG':\n",
    "    # EEG models\n",
    "    print('Model output',tf_model.classify_data(np.zeros([1,56,16,8])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
