{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "processing_source_path = os.path.abspath('./../../../Processing/')\n",
    "if(processing_source_path not in sys.path):\n",
    "    sys.path.append(processing_source_path)\n",
    "from processing import preprocessing\n",
    "from processing import posprocessing\n",
    "from processing import FeaturesExtract\n",
    "\n",
    "Utils_source_path = os.path.abspath('./../../../Utils/')\n",
    "if(Utils_source_path not in sys.path):\n",
    "    sys.path.append(Utils_source_path)\n",
    "from log_soak_test import soak_test\n",
    "\n",
    "Embedded_source_path = os.path.abspath('./../../../Quantization/functions/')\n",
    "if(Embedded_source_path not in sys.path):\n",
    "    sys.path.append(Embedded_source_path)\n",
    "from Embedded_Model import Embedded_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#protocol communication liraries\n",
    "import zmq\n",
    "import logging\n",
    "LOG_LEVEL=logging.DEBUG #change to logging.DEBUG to enable print logs\n",
    "ZEROMQ_SOCKET=\"tcp://127.0.0.1:53421\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EDGE AI Machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Params and initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ma_length=31\n",
    "window_length=128\n",
    "tke_length=1\n",
    "window_length_init=window_length+Ma_length+tke_length\n",
    "channels=64\n",
    "window_step=64\n",
    "\n",
    "window_emg= np.random.uniform(0.00001, 0,size=(1,channels,window_length))\n",
    "# initializing variables to initial conditions\n",
    "data_prev = window_emg[:,:,-Ma_length-1:].copy()\n",
    "prep_time=[]\n",
    "AI_time=[]\n",
    "all_emg_data=[]\n",
    "n_voting=5\n",
    "y_AI_array = np.zeros([n_voting])\n",
    "selected_features = ['dvar', 'iemg', 'mav', 'arv', 'cog', 'auc', 'M2', 'danv', 'var', 'dasdv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Signal Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = preprocessing(axis=2)\n",
    "ppos=posprocessing()\n",
    "features =FeaturesExtract(axis=2, selected_features=selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "with open('./../../quantized_model/model_LDA_25295225.hdf5', 'rb') as file:\n",
    "    AI_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soak test log settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communication protocol settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "subscriber = context.socket(zmq.SUB)\n",
    "subscriber.connect(ZEROMQ_SOCKET)\n",
    "subscriber.setsockopt(zmq.SUBSCRIBE, b\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main-loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soakt test time settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acc variables\n",
    "N_correct=0\n",
    "N_interactions=0\n",
    "\n",
    "# log updates time\n",
    "log_update_time= 20 #seconds\n",
    "\n",
    "# soak test total time\n",
    "duration_time= 6 # hour\n",
    "end_time= time.time()+ 60 * 60 * duration_time\n",
    "\n",
    "update_time_duration=time.time()\n",
    "classes=[0, 13, 14, 17, 20, 36, 58, 59, 63, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name=f'logs/system_monitor_machine_learning_model_during_{duration_time}_hours'\n",
    "ST=soak_test(log_name=log_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI model in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Latency: 0.2121ms | Model Predict Latency: 0.1122ms | Model  accuracy: 0.9643652561247216\n",
      "Preprocessing Latency: 0.2049ms | Model Predict Latency: 0.1013ms | Model  accuracy: 0.9774096385542169\n",
      "Preprocessing Latency: 0.214ms | Model Predict Latency: 0.1071ms | Model  accuracy: 0.9683257918552036\n",
      "Preprocessing Latency: 0.2024ms | Model Predict Latency: 0.1006ms | Model  accuracy: 0.9592760180995475\n",
      "Preprocessing Latency: 0.208ms | Model Predict Latency: 0.1065ms | Model  accuracy: 0.7164404223227753\n",
      "Preprocessing Latency: 0.22ms | Model Predict Latency: 0.1037ms | Model  accuracy: 0.9592760180995475\n",
      "Preprocessing Latency: 0.2094ms | Model Predict Latency: 0.1032ms | Model  accuracy: 0.9673024523160763\n",
      "Preprocessing Latency: 0.2188ms | Model Predict Latency: 0.1036ms | Model  accuracy: 0.9683257918552036\n",
      "Preprocessing Latency: 0.2117ms | Model Predict Latency: 0.1044ms | Model  accuracy: 0.9607843137254902\n",
      "Preprocessing Latency: 0.2066ms | Model Predict Latency: 0.1058ms | Model  accuracy: 0.975867269984917\n",
      "Preprocessing Latency: 0.2074ms | Model Predict Latency: 0.1025ms | Model  accuracy: 0.8159879336349924\n",
      "Preprocessing Latency: 0.2053ms | Model Predict Latency: 0.1053ms | Model  accuracy: 0.8629518072289156\n",
      "Preprocessing Latency: 0.2065ms | Model Predict Latency: 0.1082ms | Model  accuracy: 0.9638009049773756\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m<\u001b[39m end_time:\n\u001b[0;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msubscriber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#logging.debug(f\"recv len {len(data)} bytes from publisher\")\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#data processing start here\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Convert received data in bit(4-bytes) to numpy array\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     Data_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape(window_step,channels\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:781\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:817\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:186\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while time.time() < end_time:\n",
    "    \n",
    "    data = subscriber.recv()\n",
    "    #logging.debug(f\"recv len {len(data)} bytes from publisher\")\n",
    "    #data processing start here\n",
    "\n",
    "    # Convert received data in bit(4-bytes) to numpy array\n",
    "    Data_array = np.frombuffer(data, dtype=np.float32).reshape(window_step,channels+1).T\n",
    "    \n",
    "    label= Data_array[-1,:]\n",
    "    \n",
    "    Data_array=np.expand_dims(Data_array[:-1,:],0)\n",
    "\n",
    "    # windowing \n",
    "    window_emg=pp.moving_window(window_emg,Data_array,window_step)\n",
    "    tic=time.time()\n",
    "    #preprcessing\n",
    "\n",
    "    emg_ret=pp.retification(window_emg)\n",
    "    emg_ret= np.concatenate((data_prev, emg_ret),axis=2)\n",
    "\n",
    "    data_prev = emg_ret[:,:,-Ma_length-1:].copy()\n",
    "\n",
    "    emg_tke=pp.TKE(emg_ret)\n",
    "    \n",
    "    emg_MA=pp.MAfilter(emg_tke,N=Ma_length)\n",
    "    \n",
    "    emg_norm=pp.NormMinMax(emg_MA,new_axis=1)\n",
    "    #emg_norm=emg_MA\n",
    "    prep_time+=[time.time()-tic]\n",
    "    \n",
    "    # extract time features\n",
    "\n",
    "    features_time=features.comput_features(emg_norm,axis=2)\n",
    "    \n",
    "    features_time_norm=pp.NormMinMax(features_time,new_axis=1)\n",
    "\n",
    "    features_to_model=np.vstack(features_time_norm.flatten())\n",
    "\n",
    "    #classification\n",
    "    tic_model=time.time()\n",
    "\n",
    "    y_AI_array = np.roll(y_AI_array,-1)\n",
    "    \n",
    "    y_AI_array[-1] = AI_model.predict(features_to_model.T)\n",
    "\n",
    "    AI_time+=[time.time()-tic_model]\n",
    "\n",
    "    #pos processing \n",
    "    y_votting=ppos.majority_voting(y_AI_array, n_voting)\n",
    "\n",
    "    # Acc  \n",
    "    if y_votting == np.where(label[-1]==classes)[0]:\n",
    "        N_correct=N_correct+1\n",
    "    \n",
    "    N_interactions=N_interactions+1\n",
    "\n",
    "    #log results\n",
    "    if time.time() - update_time_duration>= log_update_time:\n",
    "        #reset log time \n",
    "        update_time_duration=time.time()\n",
    "        #comput acc\n",
    "        Acc=N_correct/N_interactions\n",
    "        print(f'Preprocessing Latency: {round(np.mean(prep_time)*1000,4)}ms | Model Predict Latency: {round(np.mean(AI_time)*1000,4)}ms | Model  accuracy: {Acc}')\n",
    "\n",
    "        # update params60*\n",
    "        ST.set_model_performance(np.mean(prep_time), np.mean(AI_time),Acc)\n",
    "        AI_time=[]\n",
    "        prep_time=[]\n",
    "        # save params \n",
    "        \n",
    "        #uncomment to save logs and display it \n",
    "        #ST.log_info()\n",
    "        \n",
    "        N_correct=0\n",
    "        N_interactions=0\n",
    "\n",
    "subscriber.close()\n",
    "context.term()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
