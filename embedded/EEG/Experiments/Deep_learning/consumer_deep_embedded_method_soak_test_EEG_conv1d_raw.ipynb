{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "processing_source_path = os.path.abspath('./../../../Processing/')\n",
    "if(processing_source_path not in sys.path):\n",
    "    sys.path.append(processing_source_path)\n",
    "from processing import preprocessing\n",
    "from processing import posprocessing\n",
    "from processing import FeaturesExtract\n",
    "\n",
    "Utils_source_path = os.path.abspath('./../../../Utils/')\n",
    "if(Utils_source_path not in sys.path):\n",
    "    sys.path.append(Utils_source_path)\n",
    "from log_soak_test import soak_test\n",
    "\n",
    "Embedded_source_path = os.path.abspath('./../../../Quantization/functions/')\n",
    "if(Embedded_source_path not in sys.path):\n",
    "    sys.path.append(Embedded_source_path)\n",
    "from Embedded_Model import Embedded_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EDGE AI Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#protocol communication liraries\n",
    "import zmq\n",
    "import logging\n",
    "LOG_LEVEL=logging.DEBUG #change to logging.DEBUG to enable print logs\n",
    "ZEROMQ_SOCKET=\"tcp://127.0.0.1:12345\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  EDGE AI pre-definitions\n",
    "pp = preprocessing(axis=1)\n",
    "ppos=posprocessing()\n",
    "features =FeaturesExtract(axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params and initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dataset_path': '/root/data/data/OpenBMI/',\n",
    "    'channels': ['O1', 'Oz', 'O2', 'PO10', 'PO9', 'POz', 'PO3', 'PO4'],\n",
    "    'freqs': [0, 12.0, 8.57, 6.67, 5.45],\n",
    "    'num_harmonics': 3,\n",
    "    'extracted_frequencies': [5,55],\n",
    "    'sfreq': 1000,\n",
    "    'window': 512,\n",
    "    'step': 64,\n",
    "    'features_type': 'psd',\n",
    "    'preprocessing': 'log10',\n",
    "    'num_repetitions': 100,\n",
    "    'num_channels': 8,\n",
    "    'num_classes':  5,\n",
    "    'num_samples': 16,\n",
    "    'num_windows': 35,\n",
    "    'window_size': 512,\n",
    "    'batchsize': 32,\n",
    "    'epochs': 100,\n",
    "    'dropout_rate': 0.5,\n",
    "    'print_model': True,\n",
    "    'num_epochs':60,\n",
    "    'num_voting': 5,\n",
    "    'output_function': 'activations.sigmoid',\n",
    "    'model_name': 'Conv2D_noBN'\n",
    "}\n",
    "\n",
    "window_EEG= np.random.uniform(0.00001, 0,size=(params['num_channels'],params['window_size']))\n",
    "prep_time=[]\n",
    "AI_time=[]\n",
    "y_AI_array = np.zeros(params['num_voting'])\n",
    "\n",
    "psd_2D = np.zeros((params['num_samples'],\n",
    "                           params['extracted_frequencies'][1]-params['extracted_frequencies'][0],\n",
    "                           params['num_channels']),dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "#AI_tf_model=Embedded_Model('./../../keras_quantized_model/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene')\n",
    "AI_tf_model=Embedded_Model('./../../keras_quantized_model/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multihead')\n",
    "#AI_tf_model2=Embedded_Model('./../../keras_quantized_model/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_custom_dataloader')\n",
    "AI_tf_model=Embedded_Model('./../../keras_quantized_model/SSVEP_CNN_1D_minmax_normalized_by_channel_data_Raw_multidense_dataloader_irene_weights')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soak test log settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communication protocol settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "subscriber = context.socket(zmq.SUB)\n",
    "subscriber.connect(ZEROMQ_SOCKET)\n",
    "subscriber.setsockopt(zmq.SUBSCRIBE, b\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main-loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soakt test time settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acc variables\n",
    "N_correct=0\n",
    "N_interactions=0\n",
    "\n",
    "# log updates time\n",
    "log_update_time= 60 #seconds\n",
    "\n",
    "# soak test total time\n",
    "duration_time= 1 # hour\n",
    "end_time= time.time()+ 60 * 60 * duration_time\n",
    "\n",
    "update_time_duration=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name=f'logs/system_monitor_deep_conv1D_raw_embedded_model_during_{duration_time}_hours_with_noise'\n",
    "ST=soak_test(log_name=log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise\n",
    "def band_limited_noise(min_freq, max_freq, samples=1024, samplerate=1):\n",
    "    freqs = np.abs(np.fft.fftfreq(samples, 1/samplerate))\n",
    "    f = np.zeros(samples)\n",
    "    idx = np.where(np.logical_and(freqs>=min_freq, freqs<=max_freq))[0]\n",
    "    f[idx] = 1\n",
    "    return fftnoise(f)\n",
    "\n",
    "def fftnoise(f):\n",
    "    f = np.array(f, dtype='complex')\n",
    "    Np = (len(f) - 1) // 2\n",
    "    phases = np.random.rand(Np) * 2 * np.pi\n",
    "    phases = np.cos(phases) + 1j * np.sin(phases)\n",
    "    f[1:Np+1] *= phases\n",
    "    f[-1:-1-Np:-1] = np.conj(f[1:Np+1])\n",
    "    return np.fft.ifft(f).real\n",
    "\n",
    "def create_noise(minimum, maximum,data_len):\n",
    "    x = band_limited_noise(10, 900, data_len, 2048)\n",
    "    x -= np.min(x)\n",
    "    x /= (np.max(x))\n",
    "    x *= (maximum-minimum)\n",
    "    x += minimum\n",
    "    return x\n",
    "max_var=15/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI model in loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m Labels\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m<\u001b[39m end_time:\n\u001b[0;32m----> 7\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msubscriber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Convert received data in bit(4-bytes) to numpy array\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     Data_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_channels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:781\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:817\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:186\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#while True:\n",
    "Data=[]\n",
    "all_labels=[]\n",
    "all_pred=[]\n",
    "Labels=[]\n",
    "while time.time() < end_time:\n",
    "    data = subscriber.recv()\n",
    "    # Convert received data in bit(4-bytes) to numpy array\n",
    "    Data_array = np.frombuffer(data, dtype=np.float32).reshape(-1,params['num_channels']+1).T.astype(np.float32)\n",
    "    \n",
    "    label= Data_array[-1,:]\n",
    "    Labels+=[label]\n",
    "    Data += [Data_array[:-1,:]]\n",
    "    \n",
    "    if len(Data)>= params['step']//64:\n",
    "        #Data_array=np.expand_dims(Data_array[:-1,:],0)\n",
    "       \n",
    "        Data_raw=np.hstack(Data)\n",
    "        '''\n",
    "        for ch in range(8):\n",
    "            noise=create_noise(np.min(np.hstack(Data)[ch,:])/max_var,np.max(np.hstack(Data)[ch,:])*max_var,np.hstack(Data).shape[1])\n",
    "            Data_raw[ch,:]=Data_raw[ch,:]+noise\n",
    "        '''  \n",
    "        \n",
    "        window_EEG=pp.moving_window(window_EEG,Data_raw,params['step'])   \n",
    "        Data=[] # reset Data \n",
    "        Labels=[]\n",
    "        tic=time.time()\n",
    "        #preprcessing\n",
    "        \n",
    "        eeg_norm=pp.NormMinMax(window_EEG,new_axis=1) # norm by sample\n",
    "        #eeg_norm=pp.NormMinMax(window_EEG,new_axis=0) # norm by channel\n",
    "\n",
    "        eeg_norm=np.expand_dims(eeg_norm,0)\n",
    "        eeg_norm=np.moveaxis(eeg_norm,1,2)\n",
    "        #emg_norm=pp.NormMinMax(np.expand_dims(window_EEG,0),new_axis=1)\n",
    "\n",
    "        prep_time+=[time.time()-tic]\n",
    "        \n",
    "\n",
    "        #classification\n",
    "        tic_model=time.time()\n",
    "\n",
    "        y_AI_array = np.roll(y_AI_array,-1)\n",
    "\n",
    "        model_pred=AI_tf_model.classify_data(eeg_norm)\n",
    "\n",
    "        if np.argmax(model_pred[0]) == 1 and np.argmax(model_pred[1]) != 0 :\n",
    "        #if np.argmax(model_pred[1]) != 0:\n",
    "            \n",
    "            #model_pred2=AI_tf_model2.classify_data(eeg_norm)\n",
    "            y_AI_array[-1] = np.argmax(model_pred[1][1:])\n",
    "\n",
    "            AI_time+=[time.time()-tic_model]\n",
    "\n",
    "            #pos processing \n",
    "            y_votting=ppos.majority_voting(y_AI_array, params['num_voting'])\n",
    "            #y_votting=y_AI_array[-1]\n",
    "\n",
    "\n",
    "            all_pred+=[y_votting.item()+1]\n",
    "            all_labels+=[label[-1]]\n",
    "            # Acc  \n",
    "            if all_pred[-1]== int(label[-1]):\n",
    "                N_correct=N_correct+1\n",
    "\n",
    "            N_interactions=N_interactions+1\n",
    "\n",
    "    #log results\n",
    "    if time.time() - update_time_duration>= log_update_time:\n",
    "        if N_interactions!= 0:\n",
    "\n",
    "            #reset log time \n",
    "            update_time_duration=time.time()\n",
    "            #comput acc\n",
    "            Acc=N_correct/N_interactions\n",
    "            # update params60*\n",
    "            #print(f'Preprocessing Latency: {round(np.mean(prep_time)*1000,4)}ms | Model Predict Latency: {round(np.mean(AI_time)*1000,4)}ms | Model  accuracy: {Acc}')\n",
    "\n",
    "            ST.set_model_performance(np.mean(prep_time), np.mean(AI_time),Acc)\n",
    "            AI_time=[]\n",
    "            prep_time=[]\n",
    "            #uncomment to save logs and display it \n",
    "            ST.log_info()\n",
    "            \n",
    "            N_correct=0\n",
    "            N_interactions=0\n",
    "        \n",
    "print(\"Média de tempo no pré-processamento\",np.array(prep_time).mean() *1000,'ms')\n",
    "print(\"Máximo tempo no pré-processamento\",np.array(prep_time).max() *1000,'ms')\n",
    "\n",
    "print(\"Média de tempo do modelo AI\",np.array(AI_time)[10:].mean() *1000,'ms')\n",
    "print(\"Máximo tempo do modelo AI\",np.array(AI_time)[10:].max() *1000,'ms')\n",
    "\n",
    "subscriber.close()\n",
    "context.term()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
