{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "processing_source_path = os.path.abspath('./../../../Processing/')\n",
    "if(processing_source_path not in sys.path):\n",
    "    sys.path.append(processing_source_path)\n",
    "from processing import preprocessing\n",
    "from processing import posprocessing\n",
    "from processing import FeaturesExtract\n",
    "\n",
    "Utils_source_path = os.path.abspath('./../../../Utils/')\n",
    "if(Utils_source_path not in sys.path):\n",
    "    sys.path.append(Utils_source_path)\n",
    "from log_soak_test import soak_test\n",
    "\n",
    "Embedded_source_path = os.path.abspath('./../../../Quantization/functions/')\n",
    "if(Embedded_source_path not in sys.path):\n",
    "    sys.path.append(Embedded_source_path)\n",
    "from Embedded_Model import Embedded_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#protocol communication liraries\n",
    "import zmq\n",
    "import logging\n",
    "LOG_LEVEL=logging.DEBUG #change to logging.DEBUG to enable print logs\n",
    "ZEROMQ_SOCKET=\"tcp://127.0.0.1:12345\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EDGE AI Deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  EDGE AI pre-definitions\n",
    "pp = preprocessing(axis=1)\n",
    "ppos=posprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params and initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dataset_path': '/root/data/data/OpenBMI/',\n",
    "    'channels': ['O1', 'Oz', 'O2', 'PO10', 'PO9', 'POz', 'PO3', 'PO4'],\n",
    "    'freqs': [0, 12.0, 8.57, 6.67, 5.45],\n",
    "    'num_harmonics': 3,\n",
    "    'extracted_frequencies': [2,58],\n",
    "    'sfreq': 1000,\n",
    "    'features_type': 'psd',\n",
    "    'preprocessing': 'log10',\n",
    "    'num_channels': 8,\n",
    "    'num_classes':  5,\n",
    "    'num_samples': 16,\n",
    "    'window_size': 1000,\n",
    "    'step': 64*2,\n",
    "    'num_voting': 3,\n",
    "    'model_name': 'Conv2D_DW_GAP',\n",
    "    'norm_axis': 3\n",
    "}\n",
    "\n",
    "window_EEG= np.random.uniform(0.00001, 0,size=(params['num_channels'],params['window_size']))\n",
    "prep_time=[]\n",
    "AI_time=[]\n",
    "y_AI_array = np.zeros(params['num_voting'])\n",
    "\n",
    "psd_2D = np.zeros((params['num_samples'],\n",
    "                           params['extracted_frequencies'][1]-params['extracted_frequencies'][0],\n",
    "                           params['num_channels']),dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "AI_tf_model=Embedded_Model('./../../keras_quantized_model/Conv2D_DW_GAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soak test log settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communication protocol settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "subscriber = context.socket(zmq.SUB)\n",
    "subscriber.connect(ZEROMQ_SOCKET)\n",
    "subscriber.setsockopt(zmq.SUBSCRIBE, b\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main-loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soakt test time settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acc variables\n",
    "N_correct=0\n",
    "N_interactions=0\n",
    "\n",
    "# log updates time\n",
    "log_update_time= 20 #seconds\n",
    "\n",
    "# soak test total time\n",
    "duration_time= 6 # hour\n",
    "end_time= time.time()+ 60 * 60 * duration_time\n",
    "\n",
    "update_time_duration=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name=f'logs/system_monitor_deep_embedded_model_during_{duration_time}_hours'\n",
    "ST=soak_test(log_name=log_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI model in loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### custom funcitons to 2D deep model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_psd(spectra, x_vector):\n",
    "    spectra = np.roll(spectra, -1, axis=0)\n",
    "    spectra[-1,:,:] = x_vector\n",
    "    \n",
    "    return spectra\n",
    "\n",
    "def calculate_psd(data, params):\n",
    "    # Obs: the best\n",
    "    # print('fft inputs', eeg.shape,rep,ch,nsteps,WinLength)\n",
    "    \n",
    "    myamp = np.array([])\n",
    "\n",
    "    (f, S)= scipy.signal.welch(data, params['sfreq'], nperseg=None, window = 'box', scaling='spectrum', nfft=int(params['sfreq']), average='median')\n",
    "\n",
    "    amp = np.abs(S)\n",
    "    amp = np.log10(amp[:,params['extracted_frequencies'][0]:params['extracted_frequencies'][1]] + sys.float_info.epsilon)\n",
    "        \n",
    "    return amp \n",
    "\n",
    "def calculate_psd(data,params):\n",
    "    \n",
    "    FourierCoeff = np.fft.fft(data)/data.shape[0]\n",
    "    amp = FourierCoeff[params['extracted_frequencies'][0]:params['extracted_frequencies'][1]]\n",
    "    amp = 2*np.abs(amp)\n",
    "        \n",
    "    return np.log10(amp)\n",
    "\n",
    "def calculate_amplitude2(data,params):\n",
    "    \n",
    "    # print('fft inputs', eeg.shape,rep,ch,nsteps,WinLength)\n",
    "    \n",
    "    myamp = np.array([])\n",
    "\n",
    "    FourierCoeff = np.fft.fft(data)/params['window_size']\n",
    "    # print('fourier',FourierCoeff.shape)\n",
    "        \n",
    "    DC = [np.abs(FourierCoeff[0])] # DC component\n",
    "    amp = np.concatenate((DC, 2*np.abs(FourierCoeff[1:len(FourierCoeff)//2])))\n",
    "    amp = np.log10(amp)\n",
    "        \n",
    "    return amp[params['extracted_frequencies'][0]:params['extracted_frequencies'][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_data(data, new_batch):\n",
    "    data = np.roll(data,-new_batch.shape[0],axis=0)\n",
    "    data[-new_batch.shape[0]:,:] = new_batch\n",
    "    \n",
    "    return data\n",
    "\n",
    "def buffer_psd(spectra, x_vector):\n",
    "    spectra = np.roll(spectra, -1, axis=0)\n",
    "    spectra[-1,:,:] = x_vector\n",
    "    \n",
    "    return spectra\n",
    "\n",
    "# calculate psd\n",
    "def calculate_psd(data, params):\n",
    "    \n",
    "    # print('fft inputs', eeg.shape,rep,ch,nsteps,WinLength)\n",
    "    \n",
    "    myamp = np.array([])\n",
    "\n",
    "    (f, S)= scipy.signal.welch(data, params['sfreq'], nperseg=None, window = 'box', scaling='spectrum', nfft=int(params['sfreq']), average='median')\n",
    "\n",
    "    amp = np.abs(S)\n",
    "    amp = np.log10(amp[ params['extracted_frequencies'][0]:params['extracted_frequencies'][1]] + sys.float_info.epsilon)\n",
    "        \n",
    "    return amp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Latency: 0.6361ms | Model Predict Latency: 8.178ms | Model  accuracy: 0.6013071895424836\n",
      "Preprocessing Latency: 0.669ms | Model Predict Latency: 8.5313ms | Model  accuracy: 0.7508090614886731\n",
      "Preprocessing Latency: 0.6927ms | Model Predict Latency: 8.7017ms | Model  accuracy: 0.6925465838509317\n",
      "Preprocessing Latency: 0.6502ms | Model Predict Latency: 8.5142ms | Model  accuracy: 0.7165109034267912\n",
      "Preprocessing Latency: 0.6184ms | Model Predict Latency: 8.1117ms | Model  accuracy: 0.7046153846153846\n",
      "Preprocessing Latency: 0.6046ms | Model Predict Latency: 8.0209ms | Model  accuracy: 0.72\n",
      "Preprocessing Latency: 0.6343ms | Model Predict Latency: 8.0248ms | Model  accuracy: 0.809375\n",
      "Preprocessing Latency: 0.5904ms | Model Predict Latency: 7.9708ms | Model  accuracy: 0.6818181818181818\n",
      "Preprocessing Latency: 0.6301ms | Model Predict Latency: 7.9763ms | Model  accuracy: 0.6644736842105263\n",
      "Preprocessing Latency: 0.7411ms | Model Predict Latency: 8.7149ms | Model  accuracy: 0.7363344051446945\n",
      "Preprocessing Latency: 0.635ms | Model Predict Latency: 8.2109ms | Model  accuracy: 0.7453416149068323\n",
      "Preprocessing Latency: 0.6743ms | Model Predict Latency: 8.5673ms | Model  accuracy: 0.7201365187713311\n",
      "Preprocessing Latency: 0.6419ms | Model Predict Latency: 8.1914ms | Model  accuracy: 0.6631944444444444\n",
      "Preprocessing Latency: 0.675ms | Model Predict Latency: 8.4519ms | Model  accuracy: 0.6340579710144928\n",
      "Preprocessing Latency: 0.6566ms | Model Predict Latency: 8.3754ms | Model  accuracy: 0.6688311688311688\n",
      "Preprocessing Latency: 0.6869ms | Model Predict Latency: 8.2692ms | Model  accuracy: 0.5116279069767442\n",
      "Preprocessing Latency: 0.7079ms | Model Predict Latency: 8.5245ms | Model  accuracy: 0.6210526315789474\n"
     ]
    }
   ],
   "source": [
    "#while True:\n",
    "Data=[]\n",
    "all_labels=[]\n",
    "all_pred=[]\n",
    "while time.time() < end_time:\n",
    "    data = subscriber.recv()\n",
    "    # Convert received data in bit(4-bytes) to numpy array\n",
    "    Data_array = np.frombuffer(data, dtype=np.float64).reshape(-1,params['num_channels']+1).T.astype(np.float32)\n",
    "    \n",
    "    label= Data_array[-1,:].astype(np.float32)\n",
    "\n",
    "    Data += [Data_array[:-1,:]]\n",
    "    \n",
    "    if len(Data)>= params['step']//64:\n",
    "        #Data_array=np.expand_dims(Data_array[:-1,:],0)\n",
    "       \n",
    "        window_EEG=pp.moving_window(window_EEG,np.hstack(Data),params['step'])   \n",
    "        Data=[] # reset Data \n",
    "\n",
    "        tic=time.time()\n",
    "        #preprcessing\n",
    "    \n",
    "        #psd_data=calculate_psd(window_EEG,params).transpose(1,0)\n",
    "        \n",
    "        psd_data=np.zeros([56,8])\n",
    "        for ch in range(params['num_channels']):\n",
    "            psd_data[:,ch]=calculate_amplitude2(window_EEG[ch,:],params)\n",
    "\n",
    "        #psd_data.shape\n",
    "        psd_2D = buffer_psd(psd_2D, psd_data)\n",
    "        psd_2D_aux=np.expand_dims(psd_2D.transpose(2,0,1),0)\n",
    "\n",
    "        norm_data=pp.NormMinMax_2D(psd_2D_aux,params['norm_axis'],0,1).transpose(0, 3, 2, 1)\n",
    "        \n",
    "        prep_time+=[time.time()-tic]\n",
    "        \n",
    "\n",
    "        #classification\n",
    "        tic_model=time.time()\n",
    "\n",
    "        y_AI_array = np.roll(y_AI_array,-1)\n",
    "\n",
    "        #model_pred=AI_tf_model.classify_data(np.expand_dims(psd_2D.transpose(1,0,2),0))\n",
    "        model_pred=AI_tf_model.classify_data(norm_data)\n",
    "\n",
    "        if np.argmax(model_pred[0]) == 1 and np.argmax(model_pred[1]) != 0 :\n",
    "        #if np.argmax(model_pred[1]) != 0:\n",
    "    \n",
    "            y_AI_array[-1] = np.argmax(model_pred[1])\n",
    "\n",
    "            AI_time+=[time.time()-tic_model]\n",
    "\n",
    "            #pos processing \n",
    "            y_votting=ppos.majority_voting(y_AI_array, params['num_voting'])\n",
    "            all_pred+=[y_votting]\n",
    "            \n",
    "            all_pred+=[y_AI_array[-1]]\n",
    "            all_labels+=[label[-1]]\n",
    "                                           \n",
    "            # Acc  \n",
    "            if (y_votting == label[-1]):\n",
    "                N_correct=N_correct+1\n",
    "            \n",
    "            N_interactions=N_interactions+1\n",
    "\n",
    "    #log results\n",
    "    if time.time() - update_time_duration>= log_update_time:\n",
    "        if N_interactions!= 0:\n",
    "\n",
    "            #reset log time \n",
    "            update_time_duration=time.time()\n",
    "            #comput acc\n",
    "            Acc=N_correct/N_interactions\n",
    "            # update params60*\n",
    "            print(f'Preprocessing Latency: {round(np.mean(prep_time)*1000,4)}ms | Model Predict Latency: {round(np.mean(AI_time)*1000,4)}ms | Model  accuracy: {Acc}')\n",
    "\n",
    "            ST.set_model_performance(np.mean(prep_time), np.mean(AI_time),Acc)\n",
    "            AI_time=[]\n",
    "            prep_time=[]\n",
    "            #uncomment to save logs and display it \n",
    "            #ST.log_info()\n",
    "            \n",
    "            N_correct=0\n",
    "            N_interactions=0\n",
    "        \n",
    "print(\"Média de tempo no pré-processamento\",np.array(prep_time).mean() *1000,'ms')\n",
    "print(\"Máximo tempo no pré-processamento\",np.array(prep_time).max() *1000,'ms')\n",
    "\n",
    "print(\"Média de tempo do modelo AI\",np.array(AI_time)[10:].mean() *1000,'ms')\n",
    "print(\"Máximo tempo do modelo AI\",np.array(AI_time)[10:].max() *1000,'ms')\n",
    "\n",
    "subscriber.close()\n",
    "context.term()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
