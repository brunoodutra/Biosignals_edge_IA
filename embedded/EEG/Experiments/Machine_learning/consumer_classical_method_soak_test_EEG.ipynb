{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "processing_source_path = os.path.abspath('./../../../Processing/')\n",
    "if(processing_source_path not in sys.path):\n",
    "    sys.path.append(processing_source_path)\n",
    "from processing import preprocessing\n",
    "from processing import posprocessing\n",
    "from processing import FeaturesExtract\n",
    "\n",
    "Utils_source_path = os.path.abspath('./../../../Utils/')\n",
    "if(Utils_source_path not in sys.path):\n",
    "    sys.path.append(Utils_source_path)\n",
    "from log_soak_test import soak_test\n",
    "\n",
    "Embedded_source_path = os.path.abspath('./../../../Quantization/functions/')\n",
    "if(Embedded_source_path not in sys.path):\n",
    "    sys.path.append(Embedded_source_path)\n",
    "from Embedded_Model import Embedded_Model\n",
    "\n",
    "\n",
    "model_source_path = os.path.abspath('./../../CCA_model/')\n",
    "if(model_source_path not in sys.path):\n",
    "    sys.path.append(model_source_path)\n",
    "\n",
    "from CCA_classify  import CCA_SSVEP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#protocol communication liraries\n",
    "import zmq\n",
    "import logging\n",
    "LOG_LEVEL=logging.DEBUG #change to logging.DEBUG to enable print logs\n",
    "ZEROMQ_SOCKET=\"tcp://127.0.0.1:12345\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EDGE AI Machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = preprocessing(axis=1)\n",
    "ppos=posprocessing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Params and initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  EEG EDGE AI pre-definitions\n",
    "pp = preprocessing(axis=1)\n",
    "ppos=posprocessing()\n",
    "\n",
    "window_length=2**11\n",
    "channels=8\n",
    "window_step=2**9\n",
    "\n",
    "samples_per_batch=64\n",
    "sfreq=1000\n",
    "window_emg= np.random.uniform(0.00001, 0,size=(channels,window_length))\n",
    "n_voting=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCA=CCA_SSVEP(sfreq=sfreq,data_length=window_length,ref_freqs = [12, 8.57, 6.67, 5.45],N_harmonics=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soak test log settings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Communication protocol settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "subscriber = context.socket(zmq.SUB)\n",
    "subscriber.connect(ZEROMQ_SOCKET)\n",
    "subscriber.setsockopt(zmq.SUBSCRIBE, b\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main-loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soakt test time settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acc variables\n",
    "N_correct=0\n",
    "N_interactions=0\n",
    "\n",
    "# log updates time\n",
    "log_update_time= 20 #seconds\n",
    "\n",
    "# soak test total time\n",
    "duration_time= 6 # hour\n",
    "end_time= time.time()+ 60 * 60 * duration_time\n",
    "\n",
    "update_time_duration=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name=f'logs/system_monitor_cca_embedded_model_during_{duration_time}_hours'\n",
    "ST=soak_test(log_name=log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "processing_source_path = os.path.abspath('./../../../../EEG/Processing/')\n",
    "if(processing_source_path not in sys.path):\n",
    "    sys.path.append(processing_source_path)\n",
    "import ProcessingPipeline as pp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_pass =  pp2.LowPassFilter(44, 1000, 5)\n",
    "high_pass = pp2.HighPassFilter(4, 1000, 5),\n",
    "anti_aliasing = pp2.LowPassFilter(100, 1000, 5),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProcessingPipeline.ProcessingPipeline"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp2.ProcessingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_processing = pp2.ProcessingPipeline([\n",
    "    # band pass\n",
    "    pp2.HighPassFilter(4, 1000, 5),\n",
    "    pp2.LowPassFilter(44, 1000, 5),\n",
    "\n",
    "    # anti aliasing\n",
    "    pp2.LowPassFilter(100, 1000, 5),\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI model in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Latency: 2.023ms | Model Predict Latency: 20.9404ms | Model  accuracy: 0.4878048780487805\n",
      "Preprocessing Latency: 2.0804ms | Model Predict Latency: 24.0051ms | Model  accuracy: 0.5609756097560976\n",
      "Preprocessing Latency: 2.2002ms | Model Predict Latency: 22.7296ms | Model  accuracy: 0.4523809523809524\n",
      "Preprocessing Latency: 1.8624ms | Model Predict Latency: 23.6468ms | Model  accuracy: 0.6097560975609756\n",
      "Preprocessing Latency: 1.9433ms | Model Predict Latency: 22.9136ms | Model  accuracy: 0.3333333333333333\n",
      "Preprocessing Latency: 1.9232ms | Model Predict Latency: 21.6739ms | Model  accuracy: 0.5121951219512195\n",
      "Preprocessing Latency: 1.9555ms | Model Predict Latency: 22.2219ms | Model  accuracy: 0.43902439024390244\n",
      "Preprocessing Latency: 1.9276ms | Model Predict Latency: 22.2701ms | Model  accuracy: 0.5238095238095238\n",
      "Preprocessing Latency: 1.9671ms | Model Predict Latency: 22.6935ms | Model  accuracy: 0.5609756097560976\n",
      "Preprocessing Latency: 1.848ms | Model Predict Latency: 23.6553ms | Model  accuracy: 0.5238095238095238\n",
      "Preprocessing Latency: 1.9222ms | Model Predict Latency: 22.8001ms | Model  accuracy: 0.2926829268292683\n",
      "Preprocessing Latency: 2.0399ms | Model Predict Latency: 23.5209ms | Model  accuracy: 0.5121951219512195\n",
      "Preprocessing Latency: 1.9992ms | Model Predict Latency: 23.9172ms | Model  accuracy: 0.38095238095238093\n",
      "Preprocessing Latency: 1.8769ms | Model Predict Latency: 23.5259ms | Model  accuracy: 0.5609756097560976\n",
      "Preprocessing Latency: 1.8909ms | Model Predict Latency: 23.2335ms | Model  accuracy: 0.3170731707317073\n",
      "Preprocessing Latency: 2.0018ms | Model Predict Latency: 23.0331ms | Model  accuracy: 0.35714285714285715\n",
      "Preprocessing Latency: 2.0067ms | Model Predict Latency: 22.2761ms | Model  accuracy: 0.43902439024390244\n",
      "Preprocessing Latency: 1.9901ms | Model Predict Latency: 23.0387ms | Model  accuracy: 0.5238095238095238\n",
      "Preprocessing Latency: 1.9717ms | Model Predict Latency: 24.6178ms | Model  accuracy: 0.4878048780487805\n",
      "Preprocessing Latency: 1.9193ms | Model Predict Latency: 24.0009ms | Model  accuracy: 0.5714285714285714\n",
      "Preprocessing Latency: 1.9586ms | Model Predict Latency: 23.1568ms | Model  accuracy: 0.24390243902439024\n",
      "Preprocessing Latency: 1.9708ms | Model Predict Latency: 22.5013ms | Model  accuracy: 0.1951219512195122\n",
      "Preprocessing Latency: 2.0075ms | Model Predict Latency: 23.0154ms | Model  accuracy: 0.30952380952380953\n",
      "Preprocessing Latency: 1.9831ms | Model Predict Latency: 23.0603ms | Model  accuracy: 0.34146341463414637\n",
      "Preprocessing Latency: 2.0424ms | Model Predict Latency: 22.4379ms | Model  accuracy: 0.1951219512195122\n",
      "Preprocessing Latency: 1.9118ms | Model Predict Latency: 23.8194ms | Model  accuracy: 0.09523809523809523\n",
      "Preprocessing Latency: 1.9051ms | Model Predict Latency: 23.6277ms | Model  accuracy: 0.5121951219512195\n",
      "Preprocessing Latency: 1.9082ms | Model Predict Latency: 24.9492ms | Model  accuracy: 0.5714285714285714\n",
      "Preprocessing Latency: 1.9537ms | Model Predict Latency: 24.7264ms | Model  accuracy: 0.5365853658536586\n",
      "Preprocessing Latency: 1.9741ms | Model Predict Latency: 27.9081ms | Model  accuracy: 0.4523809523809524\n",
      "Preprocessing Latency: 1.9101ms | Model Predict Latency: 24.2834ms | Model  accuracy: 0.43902439024390244\n",
      "Preprocessing Latency: 1.8735ms | Model Predict Latency: 22.8311ms | Model  accuracy: 0.43902439024390244\n",
      "Preprocessing Latency: 1.8288ms | Model Predict Latency: 24.4097ms | Model  accuracy: 0.5476190476190477\n",
      "Preprocessing Latency: 1.9027ms | Model Predict Latency: 24.6787ms | Model  accuracy: 0.3170731707317073\n",
      "Preprocessing Latency: 1.8776ms | Model Predict Latency: 26.6148ms | Model  accuracy: 0.42857142857142855\n",
      "Preprocessing Latency: 1.9294ms | Model Predict Latency: 20.8597ms | Model  accuracy: 0.4634146341463415\n",
      "Preprocessing Latency: 2.0156ms | Model Predict Latency: 22.3884ms | Model  accuracy: 0.5121951219512195\n",
      "Preprocessing Latency: 1.8342ms | Model Predict Latency: 24.0122ms | Model  accuracy: 0.5\n",
      "Preprocessing Latency: 1.9028ms | Model Predict Latency: 22.7822ms | Model  accuracy: 0.6585365853658537\n",
      "Preprocessing Latency: 1.8607ms | Model Predict Latency: 23.9824ms | Model  accuracy: 0.4523809523809524\n",
      "Preprocessing Latency: 2.0092ms | Model Predict Latency: 24.4281ms | Model  accuracy: 0.3170731707317073\n",
      "Preprocessing Latency: 1.917ms | Model Predict Latency: 24.3428ms | Model  accuracy: 0.40476190476190477\n",
      "Preprocessing Latency: 1.9311ms | Model Predict Latency: 24.3848ms | Model  accuracy: 0.5853658536585366\n",
      "Preprocessing Latency: 1.8505ms | Model Predict Latency: 23.7301ms | Model  accuracy: 0.4634146341463415\n",
      "Preprocessing Latency: 1.9273ms | Model Predict Latency: 23.2633ms | Model  accuracy: 0.5238095238095238\n",
      "Preprocessing Latency: 2.0545ms | Model Predict Latency: 24.1086ms | Model  accuracy: 0.4878048780487805\n",
      "Preprocessing Latency: 1.9475ms | Model Predict Latency: 23.5588ms | Model  accuracy: 0.5238095238095238\n",
      "Preprocessing Latency: 2.1555ms | Model Predict Latency: 25.3451ms | Model  accuracy: 0.34146341463414637\n",
      "Preprocessing Latency: 1.9976ms | Model Predict Latency: 22.8599ms | Model  accuracy: 0.4878048780487805\n",
      "Preprocessing Latency: 1.9132ms | Model Predict Latency: 29.0885ms | Model  accuracy: 0.5714285714285714\n",
      "Preprocessing Latency: 1.9394ms | Model Predict Latency: 24.0211ms | Model  accuracy: 0.36585365853658536\n",
      "Preprocessing Latency: 1.8753ms | Model Predict Latency: 24.8652ms | Model  accuracy: 0.5476190476190477\n"
     ]
    }
   ],
   "source": [
    "EEG_Data=[]\n",
    "prep_time=[]\n",
    "AI_time=[]\n",
    "y_CCA_array = np.zeros([n_voting])\n",
    "\n",
    "All_Y_pred=[]\n",
    "All_Y=[]\n",
    "All_Y_pred_votting=[]\n",
    "while time.time() < end_time:\n",
    "\n",
    "    data = subscriber.recv()\n",
    "    # Convert received data in bit(4-bytes) to numpy array\n",
    "    Data_array = np.frombuffer(data, dtype=np.float64).reshape(samples_per_batch,channels+1).T\n",
    "\n",
    "    label= Data_array[-1,:] -1\n",
    "    #labels, counts=np.unique(label,return_counts=True)\n",
    "\n",
    "\n",
    "    EEG_Data+=[Data_array[:-1,:,]] # wait the buffer increase\n",
    "    EEG_Data_array=np.hstack(EEG_Data)\n",
    "\n",
    "    if np.max(EEG_Data_array.shape)>=window_step:\n",
    "        tic=time.time()\n",
    "\n",
    "        #apply filters: High 1Hz, LOW 50Hz \n",
    "        #for ch in range(channels):\n",
    "        #    EEG_Data_array[ch,:]= filter_processing(EEG_Data_array[ch,:].reshape(1,-1))\n",
    "        EEG_Data_array = filter_processing(EEG_Data_array)\n",
    "\n",
    "        #mean = np.mean(EEG_Data_array, axis=(1), keepdims=True)\n",
    "        #std = np.std(EEG_Data_array, axis=(1), keepdims=True)\n",
    "        # z_scale normalization\n",
    "        #EEG_Data_array = (EEG_Data_array - mean) / std\n",
    "        \n",
    "        # windowing \n",
    "        window_eeg=pp.moving_window(window_emg,EEG_Data_array,window_step)\n",
    "\n",
    "        EEG_Data=[]\n",
    "        prep_time+=[time.time()-tic]\n",
    "        \n",
    "        tic_model=time.time()\n",
    "        # CCA model \n",
    "        y_CCA_array = np.roll(y_CCA_array,-1)\n",
    "        y_CCA_array[-1]=CCA.predict(window_eeg.T)\n",
    "        #y_votting=CCA.predict(window_eeg.T)\n",
    "        AI_time+=[time.time()-tic_model]\n",
    "    \n",
    "        #pos processing \n",
    "        y_votting=ppos.majority_voting(y_CCA_array, n_voting)\n",
    "\n",
    "        All_Y_pred+=[y_CCA_array[-1]]\n",
    "        All_Y_pred_votting+=[y_votting]\n",
    "        All_Y+=[label[-1]]\n",
    "        \n",
    "        # Acc  \n",
    "        if y_votting == label[-1]:\n",
    "            N_correct=N_correct+1\n",
    "        \n",
    "        N_interactions=N_interactions+1\n",
    "\n",
    " #log results\n",
    "    if time.time() - update_time_duration>= log_update_time:\n",
    "        if N_interactions!= 0:\n",
    "\n",
    "            #reset log time \n",
    "            update_time_duration=time.time()\n",
    "            #comput acc\n",
    "            Acc=N_correct/N_interactions\n",
    "            print(f'Preprocessing Latency: {round(np.mean(prep_time)*1000,4)}ms | Model Predict Latency: {round(np.mean(AI_time)*1000,4)}ms | Model  accuracy: {Acc}')\n",
    "\n",
    "            # update params60*\n",
    "            ST.set_model_performance(np.mean(prep_time), np.mean(AI_time),Acc)\n",
    "            AI_time=[]\n",
    "            prep_time=[]\n",
    "            # save params \n",
    "            \n",
    "            #uncomment to save logs and display it \n",
    "            #ST.log_info()\n",
    "            \n",
    "            N_correct=0\n",
    "            N_interactions=0\n",
    "\n",
    "subscriber.close()\n",
    "context.term()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_CCA_array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
